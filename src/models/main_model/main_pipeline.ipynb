{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Main Fundermentle data pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from datetime import datetime,timedelta\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.pipeline import  Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "daily_df = pd.read_csv('../../../data/main_data/DateDistric.csv')\n",
    "info_df = pd.read_csv('../../../data/main_data/Info.csv')\n",
    "district_dt_df = pd.read_csv('../../../data/main_data/EDA.csv')\n",
    "police_df = pd.read_csv('../../../data/main_data/police_report.csv')\n",
    "geo_df = pd.read_csv('../../../data/main_data/Geo_grad.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "class DateEncoder(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    def __init__(self,col_name='Date',year='2020'):\n",
    "        self.col_name = col_name\n",
    "        self.year = year\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        x = X.copy()\n",
    "        x['formal_date']= x.loc[:,'Date'].apply(lambda x: self.date_converter(x))\n",
    "        x['quarter'] = x['formal_date'].dt.quarter\n",
    "        x['date'] = x['formal_date'].dt.day\n",
    "        x['day_of_week'] = x['formal_date'].dt.dayofweek\n",
    "        x['month'] = x['formal_date'].dt.month\n",
    "        return x\n",
    "\n",
    "\n",
    "    def date_converter(self,x,year='2020'):\n",
    "        dt = str(x).split('-')\n",
    "        date = year+'/'+dt[0]+'/'+dt[1]\n",
    "        date_obj = datetime.strptime(date,'%Y/%m/%d')\n",
    "        return date_obj"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "class DatasetTuner(BaseEstimator,TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.col_order = ['index','formal_date','quarter','date','day_of_week','month','Suspected_Local','Suspected_Foreign','TotalInfected']\n",
    "        pass\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        x = X.copy()\n",
    "        x = x.rename(columns={'Unnamed: 0':'index'})\n",
    "        x = x.drop(['ID', 'Date', 'District'],axis=1)\n",
    "        #x = x.loc[:,self.col_order]\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "class WeatherTuner(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.col_order = ['index','formal_date','quarter','date','day_of_week',\n",
    "                          'month','Suspected_Local','Suspected_Foreign',\n",
    "                          'temp','humidity','sun_hours','TotalInfected']\n",
    "        pass\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        x = X.copy()\n",
    "        x = x.merge(info_df, on=[\"month\",\"index\"])\n",
    "        #x = x.loc[:,self.col_order]\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "tuning_pipe = Pipeline([\n",
    "    ('date_adder',DateEncoder()),\n",
    "    ('pre-tuner',DatasetTuner()),\n",
    "    ('weather-tuner', WeatherTuner())\n",
    "])\n",
    "\n",
    "inter_res_1 = tuning_pipe.fit_transform(daily_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "class ProvinceTuner(BaseEstimator,TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.province_dist_map = [1,1,1,2,2,2,3,3,4,4,4,5,5,6,6,6,7,7,8,8,9,9,9,9,9]\n",
    "        \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        x = X.copy()\n",
    "        x['province'] = x['index'].apply(lambda x: self.pr_ds_mapper(x))\n",
    "        return x\n",
    "\n",
    "    def pr_ds_mapper(self,x):\n",
    "        return self.province_dist_map[int(x)-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "class EDATuner(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        x = X.copy()\n",
    "        x['geo_grad']  = x['index'].map(geo_df['gradient'])\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "class NeighbourTuner(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.srr = {1:[2,3,7,8],2:[1,3,8,17,18],3:[1,4,7],4:[3,5,7],5:[4,6,7],\n",
    "           6:[5,7,13,15],7:[1,3,4,5,6,8,10,12,13],8:[1,2,7,9,10,17],\n",
    "           9:[8,10,11,12,17],10:[7,8,9,12],11:[9,12,15,17,19,20],\n",
    "           12:[7,9,10,11,15,13],13:[6,7,12,15],14:[15,16,20],15:[6,11,12,13,14,20],\n",
    "           16:[14,19,20,22,25],17:[2,8,9,11,18,19],18:[2,17,19,24],\n",
    "           19:[11,16,17,18,20,22,24],20:[5,14,15,16,19],21:[23],\n",
    "           22:[16,19,24,25],23:[21,24,25],24:[18,19,22,23,25],25:[16,22,23,24]}\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        self.x = X.copy()\n",
    "        dates = self.x['formal_date'].unique()\n",
    "        count_ser = self.repeater(dates)\n",
    "        new_lis = count_ser.values\n",
    "        if (self.x.shape[0] != len(count_ser.values)):\n",
    "            diff = self.x.shape[0]-len(count_ser.values)\n",
    "            new_lis = [0,]*diff\n",
    "            new_lis = new_lis + list(count_ser.values)\n",
    "\n",
    "        self.x['neir_infected_cases'] = new_lis\n",
    "        return self.x\n",
    "\n",
    "\n",
    "    \n",
    "    def get_date_infected(self,date):\n",
    "        date_inf = [0]+list(self.x[(self.x.loc[:,'formal_date'] == date)]['TotalInfected'].values)\n",
    "        if (len(date_inf) != 26):\n",
    "            date_inf = [0,]*26\n",
    "        return date_inf\n",
    "\n",
    "    def coverted_infected(self,date):\n",
    "        infs_day_before = self.get_date_infected(date)\n",
    "\n",
    "        inf_lis = []\n",
    "        for i in range(1,26):\n",
    "            nei_lis = self.srr[i]\n",
    "            c = 0\n",
    "            for j in nei_lis:\n",
    "                c += infs_day_before[j]\n",
    "            inf_lis.append(c)\n",
    "        inf_ser = pd.Series(data=inf_lis,index=range(1,26))\n",
    "        return inf_ser\n",
    "\n",
    "    def repeater(self,dates):\n",
    "        for j in range(len(dates)):\n",
    "            if(j == 0):\n",
    "                fin_ser = self.coverted_infected(dates[j])\n",
    "            else:\n",
    "                fin_ser = pd.concat([fin_ser,self.coverted_infected(dates[j])])\n",
    "        return fin_ser"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "class PoliceTuner(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        x = X.copy()\n",
    "        police_df['formal_date'] = police_df['formal_date'].astype(x['formal_date'].dtype)\n",
    "        x = x.merge(police_df, on=[\"index\",\"formal_date\"])\n",
    "        x['locked_percn'].fillna(0)\n",
    "        # x = x.loc[:,self.col_order]\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoTuner(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        x = X.copy()\n",
    "        x['geo_gradient'] = x['index'].map(pd.Series(data=geo_df.loc[:, \"gradient\"], index=range(1,26)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "dist_pipe = Pipeline([\n",
    "    ('province_tuner',ProvinceTuner()),\n",
    "    ('neighbour_tuner',NeighbourTuner()),\n",
    "    ('police_tuner',PoliceTuner()),\n",
    "])\n",
    "inter_res_2 = dist_pipe.fit_transform(inter_res_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "class FinalTuner(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.col_order = ['index','formal_date','quarter','date','day_of_week',\n",
    "                          'month','Suspected_Local','Suspected_Foreign',\n",
    "                          'temp','humidity','sun_hours','province',\n",
    "                          'neir_infected_cases','locked_percn','geo_gradient','TotalInfected']\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        x = X.copy()\n",
    "        x=x.sort_values(by='formal_date',ascending=True)\n",
    "        x.reset_index(inplace=True)\n",
    "        x.drop('level_0',axis=1,inplace=True)\n",
    "        x=x.fillna(0.5)\n",
    "        x = x.loc[:,self.col_order]\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "testset generating code"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "class TestTuner(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    def __init__(self,date):\n",
    "        self.date = date\n",
    "        \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        test_df_1  = pd.DataFrame(data={\n",
    "            'index': range(1,26),\n",
    "            'formal_date' : self.date_converter(self.date)\n",
    "        })\n",
    "        test_df_1['quarter'] = test_df_1['formal_date'].dt.quarter\n",
    "        test_df_1['date'] = test_df_1['formal_date'].dt.day\n",
    "        test_df_1['day_of_week'] = test_df_1['formal_date'].dt.dayofweek\n",
    "        test_df_1['month'] = test_df_1['formal_date'].dt.month\n",
    "        return test_df_1\n",
    "    \n",
    "    def date_converter(self,x,year='2020'):\n",
    "        dt = str(x).split('-')\n",
    "        date = year+'/'+dt[0]+'/'+dt[1]\n",
    "        date_obj = datetime.strptime(date,'%Y/%m/%d')\n",
    "        return date_obj"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddPastTuner(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, days, df):\n",
    "        self.days = days*25\n",
    "        self.train_df = df\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        x = X.copy()\n",
    "        self.train_df.sort_values(by=['formal_date'], inplace=True)\n",
    "        sub_train = self.train_df.iloc[:-self.days, :]\n",
    "        # train_cols = sub_train.columns\n",
    "        # test_cols = x.columns\n",
    "        # for i in train_cols:\n",
    "            # if i not in test_cols:\n",
    "                # test_cols[i] = 0\n",
    "        \n",
    "        full_test = pd.concat([sub_train,x], axis=0)\n",
    "        #x = full_test.drop('formal_date',axis=1)\n",
    "        return full_test\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "class YesterdayTuner(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    def __init__(self,source):\n",
    "        self.source = source\n",
    "        self.col_order = ['index','formal_date','quarter', 'date', 'day_of_week', 'month',\n",
    "       'Suspected_Local', 'Suspected_Foreign', 'temp', 'humidity', 'sun_hours',\n",
    "       'province', 'neir_infected_cases', 'locked_percn', 'geo_gradient',]\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        x = X.copy()\n",
    "        day_before = x.at[0,'formal_date'] - timedelta(days=1)\n",
    "        filtered_df = self.source[self.source['formal_date'] == day_before]\n",
    "        self.merger = filtered_df.loc[:,['index','neir_infected_cases','locked_percn','Suspected_Local','Suspected_Foreign']]\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        x = X.copy()\n",
    "        x = x.merge(self.merger,on='index')\n",
    "        x = x.loc[:, self.col_order]\n",
    "        x = x.fillna(0.5)\n",
    "        x['TotalInfected'] = 0\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "train_pipe = Pipeline([\n",
    "    ('date_adder',DateEncoder()),\n",
    "    ('pre-tuner',DatasetTuner()),\n",
    "    ('weather-tuner', WeatherTuner()),\n",
    "    ('province_tuner',ProvinceTuner()),\n",
    "    ('neighbour_tuner',NeighbourTuner()),\n",
    "    ('geo_grad_tuner', GeoTuner()),\n",
    "    ('police_tuner',PoliceTuner()),\n",
    "    ('final_tuner',FinalTuner()),\n",
    "])\n",
    "#('eda_tuner',EDATuner()),"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "train_df = train_pipe.fit_transform(daily_df)\n",
    "train_df.to_csv('../../../data/main_data/final_train.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "test_pipe = Pipeline([\n",
    "    ('test_tuner',TestTuner('10-31')),\n",
    "    ('weather-tuner', WeatherTuner()),\n",
    "    ('geo_grad_tuner', GeoTuner()),\n",
    "    ('province_tuner',ProvinceTuner()),\n",
    "    ('yesterday_tuner',YesterdayTuner(train_df)),\n",
    "    ('finla_touch', AddPastTuner(2, train_df))\n",
    "])\n",
    " #"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "test_df = test_pipe.fit_transform(pd.DataFrame())\n",
    "test_df.to_csv('../../../data/main_data/final_test.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.head()"
   ]
  },
  {
   "source": [
    "class Arima:\n",
    "\n",
    "    def __init__(self,dataset):\n",
    "        self.df = dataset.copy()\n",
    "        self.pdq_dist = [(1, 1, 3),(4, 2, 2),(3, 0, 5),(1, 1, 3),(3, 1, 5),\n",
    "                            (1, 1, 4),(3, 1, 5),(2, 0, 4),(3, 0, 5),(2, 1, 5),\n",
    "                            (5, 1, 3),(5, 1, 5),(2, 1, 5),(0, 1, 3),(0, 1, 4),\n",
    "                            (2, 0, 5),(1, 0, 3),(3, 0, 1),(3, 0, 5),(2, 0, 4),\n",
    "                            (4, 0, 3),(0, 0, 3),(0, 0, 0),(0, 0, 0),(0, 0, 0)]\n",
    "        self.predictions = []\n",
    "\n",
    "    def train(self):\n",
    "        for i in range(1,26):\n",
    "            res = self.arima(i,params=self.pdq_dist[i-1])\n",
    "            self.predictions.append(res)\n",
    "        return self.predictions\n",
    "\n",
    "    def custom_train(self):\n",
    "        return self.pdq_dist\n",
    "\n",
    "    def roll(self,district):\n",
    "        tmp_df = self.df.loc[self.df['index'] == district]\n",
    "        tmp_df = tmp_df.loc[:,['formal_date','TotalInfected']]\n",
    "        tmp_df = tmp_df.set_index('formal_date')\n",
    "        tmp_df.astype('int64')\n",
    "        res_df = tmp_df.rolling(window=4,center=False).mean().dropna()\n",
    "        return res_df\n",
    "\n",
    "    #Mean absolute percentage error.\n",
    "    def mape(self,y1,y_pred):\n",
    "        y1, y_pred = np.array(y1), np.array(y_pred)\n",
    "        return np.mean(np.abs((y1 - y_pred) / y1)) * 100\n",
    "\n",
    "\n",
    "    #Arima modeling for ts\n",
    "    def arima(self,district,params = (999,999,999),st=7):\n",
    "        ts = self.roll(district)\n",
    "        p=d=q=range(0,6)\n",
    "        a=99999\n",
    "        pdq=list(itertools.product(p,d,q))\n",
    "        #Determining the best parameters\n",
    "        param = (0,0,0)\n",
    "        if(params == (999,999,999)):\n",
    "            for var in pdq:\n",
    "                try:\n",
    "                    model = ARIMA(ts, order=var)\n",
    "                    result = model.fit()\n",
    "\n",
    "                    if (result.aic<=a) :\n",
    "                        a=result.aic\n",
    "                        param=var\n",
    "                except:\n",
    "                    continue\n",
    "        else:\n",
    "            param = params\n",
    "\n",
    "        #Modeling\n",
    "        model = ARIMA(ts, order=param)\n",
    "        result = model.fit()\n",
    "        result.plot_predict(start=int(len(ts) * 0.7), end=int(len(ts) * 1.2))\n",
    "        pred=result.forecast(steps=st)[0]\n",
    "        #Plotting results\n",
    "        f,ax=plt.subplots()\n",
    "        #plt.plot(pred,c='green', label= 'predictions')\n",
    "        #plt.plot(test, c='red',label='real values')\n",
    "        #plt.legend()\n",
    "        #plt.title('True vs predicted values')\n",
    "        #Printing the error metrics\n",
    "        print(result.summary())\n",
    "\n",
    "        #print('\\nMean absolute percentage error: %f'%self.mape(test,pred))\n",
    "        return result.forecast(steps=1)[0]"
   ],
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "source": [
    "class RFRWalkingForward:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.fixed_params = {'bootstrap':  False,\n",
    "             'n_estimators': 80,\n",
    "             'max_features':  0.65,\n",
    "             'min_samples_leaf':10,\n",
    "             'min_samples_split': 3 }\n",
    "\n",
    "# declare the classifier\n",
    "    def train(self,df):\n",
    "        self.mdl = RandomForestRegressor(bootstrap=self.fixed_params['bootstrap'],\n",
    "                                      n_estimators=self.fixed_params['n_estimators'],\n",
    "                                      max_features=self.fixed_params['max_features'],\n",
    "                                      min_samples_leaf=self.fixed_params['min_samples_leaf'],\n",
    "                                      min_samples_split=self.fixed_params['min_samples_split'])\n",
    "        RMSE = []\n",
    "        for sequence in range(5, (df.shape[0]//125)-2):\n",
    "                train = df.iloc[:sequence*125,:]\n",
    "                test = df.iloc[sequence*125:(sequence+1)*125,:]\n",
    "\n",
    "                X_train, X_test = train.drop(['formal_date','TotalInfected'], axis=1), test.drop(['formal_date','TotalInfected'], axis=1)\n",
    "                y_train, y_test = train['TotalInfected'].values, test['TotalInfected'].values\n",
    "\n",
    "                self.mdl.fit(X_train, y_train)\n",
    "                y_pred = self.mdl.predict(X_test)\n",
    "                error = sklearn.metrics.mean_squared_error(test['TotalInfected'].values, y_pred)\n",
    "                RMSE.append(error)\n",
    "        print('Mean RMSE = %.5f' % np.mean(RMSE))\n",
    "\n",
    "    def predict(self,X):\n",
    "        x = X.copy()\n",
    "        return self.mdl.predict(x)"
   ],
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "source": [
    "arima_test = Arima(train_df)\n",
    "res_1 = arima_test.train()"
   ],
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "source": [
    "rfr = RFRWalkingForward()\n",
    "rfr.train(train_df)\n",
    "res_2 = rfr.predict(test_df)"
   ],
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "source": [
    "print(res_2)"
   ],
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "# ls_1 = list(res_1)\n",
    "# ls_2 = list(res_2)\n",
    "# lis_3 = [(ls_1[i]+ls_2[i])/2 for i in range(25)]\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_axes(lis_3)\n",
    "# langs = ['Colombo','Gampaha','Kaluthara','Galle','Mathara',\n",
    "#          'Hambanthota','Rathnapura','Kegalle','Kandy',\n",
    "#          'NuwaraEliya','Matale','Badulla','Monaragale',\n",
    "#          'Batticoloa','Ampara','Trincomalee','Puttalama',\n",
    "#          'Anuradhapura','Polonnaruva','Jaffna','Killinochchi',\n",
    "#          'Mannar','Mullathiv']\n",
    "# students = [23,17,35,29,12]\n",
    "# ax.bar(langs,students)\n",
    "# plt.show()\n",
    "print('hello')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}